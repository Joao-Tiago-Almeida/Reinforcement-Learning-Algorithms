{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem_1 as mz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 : The Maze and the Random Minotaur\n",
    "\n",
    "\n",
    "For some unknown reasons you wake up inside a maze (shown in figure 1) in position A. At the same time, there is a minotaur at the exit, in B. The minotaur follows a random walk while staying within the limits of the maze, and can walk inside the walls. This means that for example, if the minotaur is not in a cell at one of the borders of the maze, then it moves to the cell above, below, on the right, and on the left with the same probability 1/4. You cannot walk inside walls, and at a given cell, you may decide to move to an adjacent cell or to stay still. At each step, you observe the position of the minotaur, and decide on a one-step move (up, down, right or left) or not to move. If the minotaur catches you, it will eat you.3 Your objective is to identify a strategy maximizing the probability of exiting the maze (reaching B) before time T.\n",
    "\n",
    "_Note 1: Neither you nor the minotaur can walk diagonally._\n",
    "\n",
    "_Note 2: The minotaur catches you, if and only if, you are located at the same position, at the same time._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question - A\n",
    "\n",
    "# Description of the maze as a numpy array\n",
    "maze = np.array([\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 0]\n",
    "])\n",
    "# with the convention\n",
    "# 0 = empty cell\n",
    "# 1 = obstacle\n",
    "# 2 = exit of the Maze\n",
    "\n",
    "# mz.draw_maze(maze)\n",
    "\n",
    "# Create an environment maze\n",
    "env = mz.Maze(maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question - B\n",
    "\n",
    "# Finite horizon\n",
    "horizon = 20\n",
    "\n",
    "# Solve the MDP problem with dynamic programming \n",
    "V, policy, minotaurs_path = mz.dynamic_programming(env,horizon,True);\n",
    "\n",
    "\n",
    "# Simulate the shortest path starting from position A\n",
    "method = 'DynProg';\n",
    "start  = (0,0);\n",
    "path,_ = env.simulate(start, policy, method);\n",
    "mz.animate_solution(maze,path,minotaurs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question - C \n",
    "\n",
    "H_list=[]\n",
    "P_list_stay=[]\n",
    "P_list_not_stay=[]\n",
    "p=1000\n",
    "\n",
    "for horizon in range(31):\n",
    "    d_mcm0, _ = mz.monte_carlo_method(p=p,start=start,maze=maze,horizon=horizon,env=env,method=method,minotaurs_stay=True)\n",
    "    if len(d_mcm0) > 1:\n",
    "        P_list_stay.append(100*d_mcm0[0]/(d_mcm0[0]+d_mcm0[1]))\n",
    "    else:\n",
    "        P_list_stay.append(100)\n",
    "    d_mcm0, _ = mz.monte_carlo_method(p=p,start=start,maze=maze,horizon=horizon,env=env,method=method,minotaurs_stay=False)\n",
    "    if len(d_mcm0) > 1:\n",
    "        P_list_not_stay.append(100*d_mcm0[0]/(d_mcm0[0]+d_mcm0[1]))\n",
    "    else:\n",
    "        P_list_not_stay.append(100)\n",
    "    \n",
    "    H_list.append(horizon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(H_list, P_list_stay, label='Stay', c='r', lw=2)\n",
    "ax.plot(H_list, P_list_not_stay, label='Not Stay', c='g', lw=2)\n",
    "ax.set_title('Probability of leaving the maze for several time horizon')\n",
    "ax.set_xlabel('Horizon')\n",
    "ax.set_ylabel('Probability of exiting the maze (in %)')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "plt.savefig('fig_question_C')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question - D\n",
    "\n",
    "discount_factor = 29/30\n",
    "epsilon = 0.0001\n",
    "V, policy = mz.value_iteration(env,discount_factor, epsilon)\n",
    "path, _ = env.simulate((0,0), policy, 'ValIter', life_0 = mz.starting_life(30))\n",
    "mz.animate_solution(maze,path,mz.randomize_minotaur_path(start = (6,5), maze_dimensions = maze.shape, T = len(path)-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V[env.map[start]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question - E\n",
    "\n",
    "p = 10000\n",
    "exiting = 0\n",
    "GEOM = np.random.geometric(p=1-discount_factor, size=p)\n",
    "\n",
    "for i in range(p):\n",
    "    path, _ = env.simulate((0,0), policy, 'ValIter', life_0 = mz.starting_life(30))\n",
    "    if GEOM[i] > len(path) or path[GEOM[i]-1] == 'WIN' or (path[GEOM[i]-1][0] == (6,5) and path[GEOM[i]-1][1] != (6,5)):\n",
    "        #Every possibility that means that the player has won the game\n",
    "        exiting += 1\n",
    "print(f\"Probability of exiting the maze is {exiting/p} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question G\n",
    "\n",
    "# add the intermidiate state - C\n",
    "mazeC, mazeB = maze.copy(), maze.copy()\n",
    "mazeC[6,5], mazeC[0,7], mazeB[0,7] = 0, 2, -2\n",
    "envC, envB = mz.Maze(mazeC), mz.Maze(mazeB)\n",
    "\n",
    "discount_factor, epsilon, life_0 = 0.99, 0.0001, mz.starting_life(50)\n",
    "\n",
    "_, policyC = mz.value_iteration(envC,discount_factor, epsilon)\n",
    "\n",
    "pathC, life_felft = envC.simulate((0,0), policyC, 'ValIter', life_0)\n",
    "if(life_felft>0 and pathC[-1]==(0,7)):\n",
    "\n",
    "    _, policyB = mz.value_iteration(envB,discount_factor, epsilon)\n",
    "    pathB, life_felft = envB.simulate(pathC[-1], policyB, 'ValIter',life_0 = life_felft)    \n",
    "\n",
    "    if (life_felft>0 and pathB[-1]==(6,5)):\n",
    "\n",
    "        pathA = pathC[:-2]+pathB\n",
    "\n",
    "        minotaurs_path = [(6,5)]\n",
    "        for t in range(len(pathA)):\n",
    "            if random.uniform(0,1) < 0.65:\n",
    "                move = mz.randomize_minotaur_path(start = minotaurs_path[-1], maze_dimensions = maze.shape, T = 1)[1]\n",
    "            else:\n",
    "                move = mz.orientated_minotaur_path(start = minotaurs_path[-1], goal = np.array(pathA[t]), T = 1)\n",
    "\n",
    "            minotaurs_path.append(move)   \n",
    "        \n",
    "        mz.animate_solution(mazeB,pathA,minotaurs_path)\n",
    "        print(f\"Initial life of {life_0} is enough to get the key and to leave the Maze\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Initial life of {life_0} is not enough to leave the Maze\")\n",
    "else:\n",
    "    print(f\"Initial life of {life_0} is not enough to take the key\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question H-2 and # Question H-3\n",
    "\n",
    "mazeC, mazeB = maze.copy(), maze.copy()\n",
    "mazeC[6,5], mazeC[0,7], mazeB[0,7] = 0, 2, -2\n",
    "envC, envB = mz.Maze(mazeC), mz.Maze(mazeB)\n",
    "\n",
    "epsilon = 0.5\n",
    "discount_factor = 0.8\n",
    "alpha = 2/3\n",
    "algotithm = \"Q-Learning\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Q_c_qlearning, policy_qlearning_C = mz.q_learning_or_sarsa(envC, discount_factor, epsilon=epsilon, alpha=alpha, algorithm = algotithm, start = (0,0), axes=ax)\n",
    "Q_b_qlearning, policy_qlearning_B = mz.q_learning_or_sarsa(envB, discount_factor, epsilon=epsilon, alpha=alpha, algorithm = algotithm, start = (0,7), axes=ax)\n",
    "\n",
    "plt.grid(axis = 'y')\n",
    "plt.title(f'Evolution of the Value Function over episodes with Q - Learning')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Sum of the value function')\n",
    "plt.legend(('Start   ->   Key','Key     ->   Exit'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mz.f(policy_qlearning_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question I-2 and # Question I-3\n",
    "\n",
    "mazeC, mazeB = maze.copy(), maze.copy()\n",
    "mazeC[6,5], mazeC[0,7], mazeB[0,7] = 0, 2, -2\n",
    "envC, envB = mz.Maze(mazeC), mz.Maze(mazeB)\n",
    "\n",
    "epsilon = 0.2\n",
    "discount_factor = 0.8\n",
    "alpha = 2/3\n",
    "algotithm = \"SARSA\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Q_c_sarsa, policy_sarsa_C = mz.q_learning_or_sarsa(envC, discount_factor=discount_factor, epsilon=epsilon, alpha=alpha, algorithm = algotithm, start = (0,0), axes=ax, Q = np.zeros(shape=(40,5)))\n",
    "Q_b_sarsa, policy_sarsa_B = mz.q_learning_or_sarsa(envB, discount_factor=discount_factor, epsilon=epsilon, alpha=alpha, algorithm = algotithm, start = (0,7), axes=ax, Q = np.zeros(shape=(40,5)))\n",
    "\n",
    "plt.grid(axis = 'y')\n",
    "plt.title(f'Evolution of the Value Function over episodes with SARSA')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Sum of the value function')\n",
    "plt.legend(('Start   ->   Key','Key     ->   Exit'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mz.f(policy_sarsa_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of path for Q learning and Sarsa\n",
    "\n",
    "start = (0,0)\n",
    "key = (0,7)\n",
    "exit = (6,5)\n",
    "\n",
    "P_exit_qlearning = []\n",
    "P_exit_sarsa = []\n",
    "horizon = []\n",
    "\n",
    "# policy_qlearning_C, policy_sarsa_C = policyC, policyC\n",
    "# policy_qlearning_B, policy_sarsa_B = policyB, policyB\n",
    "\n",
    "probability = lambda d: 100*d[0]/(d[0]+d[1]+d[2]) if d[0]!=0 else 0\n",
    "\n",
    "\n",
    "for life_0 in range(0, 51):    # for each life\n",
    "    \n",
    "    d_results_qlearning = {0:0,1:0,2:0}\n",
    "    d_results_sarsa = {0:0,1:0,2:0}\n",
    "\n",
    "\n",
    "    for h in range(100):       # Try 100 times for eaach life\n",
    "\n",
    "        # Run minotaur\n",
    "        minotaurs_path = mz.randomize_minotaur_path(start = exit, maze_dimensions = maze.shape, T = life_0+1)\n",
    "\n",
    "        # Q-Learning\n",
    "        pathC, life_felft = envC.simulate(start, policy_qlearning_C, 'ValIter', life_0 = life_0)\n",
    "        \n",
    "        if(life_felft>0 and pathC[-1]==key):\n",
    "            pathB, life_felft = envB.simulate(pathC[-1], policy_qlearning_B, 'ValIter',life_0 = life_felft)    \n",
    "\n",
    "            if (life_felft>0 and pathB[-1]==exit):\n",
    "\n",
    "                pathA = pathC[:-2]+pathB  \n",
    "\n",
    "                d_results_qlearning[\n",
    "                    mz.path_result(pathA,minotaurs_path,tuple(exit))\n",
    "                ] += 1\n",
    "\n",
    "        # Q-SARSA\n",
    "        pathC, life_felft = envC.simulate(start, policy_sarsa_C, 'ValIter', life_0 = life_0)\n",
    "        \n",
    "        if(life_felft>0 and pathC[-1]==key):\n",
    "            pathB, life_felft = envB.simulate(pathC[-1], policy_sarsa_B, 'ValIter',life_0 = life_felft)    \n",
    "\n",
    "            if (life_felft>0 and pathB[-1]==exit):\n",
    "\n",
    "                pathA = pathC[:-2]+pathB  \n",
    "\n",
    "                d_results_sarsa[\n",
    "                    mz.path_result(pathA,minotaurs_path,tuple(exit))\n",
    "                ] += 1\n",
    "\n",
    "    # store the probabilities\n",
    "    P_exit_qlearning.append(probability(d_results_qlearning))\n",
    "    P_exit_sarsa.append(probability(d_results_sarsa))\n",
    "    horizon.append(life_0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(horizon, P_exit_qlearning, label='Q-Learning', c='r', lw=2)\n",
    "ax.plot(horizon, P_exit_sarsa, label='SARSA', c='g', lw=2)\n",
    "ax.set_title('Probability of leaving the maze for different policies')\n",
    "ax.set_xlabel('Horizon')\n",
    "ax.set_ylabel('Probability of exiting the maze (in %)')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "plt.savefig('fig_question_i')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70b38d7a306a849643e446cd70466270a13445e5987dfa1344ef2b127438fa4d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
